{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d0b7812",
   "metadata": {},
   "source": [
    "# Use Delta Tables in Apache Spark\n",
    "https://microsoftlearning.github.io/mslearn-fabric/Instructions/Labs/03-delta-lake.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ba62bc",
   "metadata": {},
   "source": [
    "## load from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953014e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, IntegerType, StringType, DoubleType\n",
    "\n",
    "# define the schema\n",
    "schema = StructType() \\\n",
    ".add(\"ProductID\", IntegerType(), True) \\\n",
    ".add(\"ProductName\", StringType(), True) \\\n",
    ".add(\"Category\", StringType(), True) \\\n",
    ".add(\"ListPrice\", DoubleType(), True)\n",
    "\n",
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").schema(schema).load(\"Files/products/products.csv\")\n",
    "# df now is a Spark DataFrame containing CSV data from \"Files/products/products.csv\".\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d3ed1f",
   "metadata": {},
   "source": [
    "## create delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"delta\").saveAsTable(\"managed_products\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d91f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table can be saved elsewhere with metadata still in the lakehouse\n",
    "path = \"abfss://Learn_fabriks@onelake.dfs.fabric.microsoft.com/Lake_exo_2.Lakehouse/Files/external_products\"\n",
    "\n",
    "df.write.format(\"delta\").saveAsTable(\"external_products\", path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e37690",
   "metadata": {},
   "source": [
    "## use sql to \"describe\"/\"drop\"/\"create\" table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DESCRIBE FORMATTED external_products;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee1b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE managed_products;\n",
    "DROP TABLE external_products;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced171e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE TABLE products\n",
    "USING DELTA\n",
    "LOCATION 'Files/external_products';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d3ff98",
   "metadata": {},
   "source": [
    "## Explore table versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86d628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "UPDATE products\n",
    "SET ListPrice = ListPrice * 0.9\n",
    "WHERE Category = 'Mountain Bikes';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f366675",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DESCRIBE HISTORY products;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8389aa74",
   "metadata": {},
   "source": [
    "## Get specific verison of table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad9e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_table_path = 'Files/external_products'\n",
    "# Get the current data\n",
    "current_data = spark.read.format(\"delta\").load(delta_table_path)\n",
    "display(current_data)\n",
    "\n",
    "# Get the version 0 data\n",
    "original_data = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_table_path)\n",
    "display(original_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eb8489",
   "metadata": {},
   "source": [
    "## analyse data with SQL - create a view and select data to plot within notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6520fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Create a temporary view\n",
    "CREATE OR REPLACE TEMPORARY VIEW products_view\n",
    "AS\n",
    "    SELECT Category, COUNT(*) AS NumProducts, MIN(ListPrice) AS MinPrice, MAX(ListPrice) AS MaxPrice, AVG(ListPrice) AS AvgPrice\n",
    "    FROM products\n",
    "    GROUP BY Category;\n",
    "\n",
    "SELECT *\n",
    "FROM products_view\n",
    "ORDER BY Category;    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ac66c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT Category, NumProducts\n",
    "FROM products_view\n",
    "ORDER BY NumProducts DESC\n",
    "LIMIT 10;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1998c4ce",
   "metadata": {},
   "source": [
    "## analyse data with spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef5dce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, desc\n",
    "\n",
    "df_products = spark.sql(\"SELECT Category, MinPrice, MaxPrice, AvgPrice FROM products_view\").orderBy(col(\"AvgPrice\").desc())\n",
    "display(df_products.limit(6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730d96b",
   "metadata": {},
   "source": [
    "## Use Delta tables for streaming data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb2274f",
   "metadata": {},
   "source": [
    "### create source for streaming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1d3dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebookutils import mssparkutils\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Create a folder\n",
    "inputPath = 'Files/data/'\n",
    "mssparkutils.fs.mkdirs(inputPath)\n",
    "\n",
    "# Create a stream that reads data from the folder, using a JSON schema\n",
    "jsonSchema = StructType([\n",
    "StructField(\"device\", StringType(), False),\n",
    "StructField(\"status\", StringType(), False)\n",
    "])\n",
    "iotstream = spark.readStream.schema(jsonSchema).option(\"maxFilesPerTrigger\", 1).json(inputPath)\n",
    "\n",
    "# Write some event data to the folder\n",
    "device_data = '''{\"device\":\"Dev1\",\"status\":\"ok\"}\n",
    "{\"device\":\"Dev1\",\"status\":\"ok\"}\n",
    "{\"device\":\"Dev1\",\"status\":\"ok\"}\n",
    "{\"device\":\"Dev2\",\"status\":\"error\"}\n",
    "{\"device\":\"Dev1\",\"status\":\"ok\"}\n",
    "{\"device\":\"Dev1\",\"status\":\"error\"}\n",
    "{\"device\":\"Dev2\",\"status\":\"ok\"}\n",
    "{\"device\":\"Dev2\",\"status\":\"error\"}\n",
    "{\"device\":\"Dev1\",\"status\":\"ok\"}'''\n",
    "\n",
    "mssparkutils.fs.put(inputPath + \"data.txt\", device_data, True)\n",
    "\n",
    "print(\"Source stream created...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1640247",
   "metadata": {},
   "source": [
    "### create table for data destination (created from spark.readStream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166f836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the stream to a delta table\n",
    "delta_stream_table_path = 'Tables/iotdevicedata'\n",
    "checkpointpath = 'Files/delta/checkpoint'\n",
    "deltastream = iotstream.writeStream.format(\"delta\").option(\"checkpointLocation\", checkpointpath).start(delta_stream_table_path)\n",
    "print(\"Streaming to delta sink...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa52178",
   "metadata": {},
   "source": [
    "### add data as streaming source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710fb193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more data to the source stream\n",
    "more_data = '''{\"device\":\"Dev1\",\"status\":\"ok\"}\n",
    "{\"device\":\"Dev1\",\"status\":\"ok\"}\n",
    "{\"device\":\"Dev1\",\"status\":\"ok\"}\n",
    "{\"device\":\"Dev1\",\"status\":\"ok\"}\n",
    "{\"device\":\"Dev1\",\"status\":\"error\"}\n",
    "{\"device\":\"Dev2\",\"status\":\"error\"}\n",
    "{\"device\":\"Dev1\",\"status\":\"ok\"}'''\n",
    "\n",
    "mssparkutils.fs.put(inputPath + \"more-data.txt\", more_data, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff8b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is added to the delta table automatically\n",
    "\n",
    "%%sql\n",
    "SELECT * FROM IotDeviceData;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee7fcf",
   "metadata": {},
   "source": [
    "### stop the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltastream.stop()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
